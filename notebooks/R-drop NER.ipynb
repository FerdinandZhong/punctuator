{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ldap_home/qishuai.zhong/miniconda3/envs/punctuator_env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Reusing dataset conll2003 (/ldap_home/qishuai.zhong/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 629.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "    num_rows: 14041\n",
      "}) Dataset({\n",
      "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "    num_rows: 3250\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "validation_dataset = dataset[\"validation\"]\n",
    "\n",
    "print(train_dataset, validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5305, 2471, 6468, 10664, 791, 1186, 13455, 8779, 1542, 5991]\n",
      "[['BRUSSELS', '1996-08-22'], ['The', 'European', 'Commission', 'said', 'on', 'Thursday', 'it', 'disagreed', 'with', 'German', 'advice', 'to', 'consumers', 'to', 'shun', 'British', 'lamb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.'], ['\"', 'We', 'do', \"n't\", 'support', 'any', 'such', 'recommendation', 'because', 'we', 'do', \"n't\", 'see', 'any', 'grounds', 'for', 'it', ',', '\"', 'the', 'Commission', \"'s\", 'chief', 'spokesman', 'Nikolaus', 'van', 'der', 'Pas', 'told', 'a', 'news', 'briefing', '.'], ['He', 'said', 'further', 'scientific', 'study', 'was', 'required', 'and', 'if', 'it', 'was', 'found', 'that', 'action', 'was', 'needed', 'it', 'should', 'be', 'taken', 'by', 'the', 'European', 'Union', '.'], ['The', 'EU', \"'s\", 'scientific', 'veterinary', 'and', 'multidisciplinary', 'committees', 'are', 'due', 'to', 're-examine', 'the', 'issue', 'early', 'next', 'month', 'and', 'make', 'recommendations', 'to', 'the', 'senior', 'veterinary', 'officials', '.']] [2, 30, 33, 25, 26] [[5, 0], [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0], [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] [2, 30, 33, 25, 26]\n"
     ]
    }
   ],
   "source": [
    "# sample 5000 for training\n",
    "\n",
    "import random\n",
    "\n",
    "index_list = [index for index, _ in enumerate(train_dataset[\"tokens\"])]\n",
    "random.seed(7)\n",
    "\n",
    "sample_indexes = random.sample(index_list, 5000)\n",
    "print(sample_indexes[:10])\n",
    "\n",
    "training_corpus = [sequence for index, sequence in enumerate(train_dataset[\"tokens\"]) if index in sample_indexes]\n",
    "training_tags = [tags for index, tags in enumerate(train_dataset[\"ner_tags\"]) if index in sample_indexes]\n",
    "\n",
    "print(training_corpus[:5], [len(sequence) for sequence in training_corpus[:5]],  training_tags[:5], [len(sequence) for sequence in training_tags[:5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    }
   ],
   "source": [
    "# get the longest sentence\n",
    " \n",
    "lengths = [len(text) for text in training_corpus]\n",
    "print(max(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbpunctuator.training import NERTrainingArguments, NERTrainingPipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "training_args = NERTrainingArguments(\n",
    "    training_corpus = training_corpus,\n",
    "    validation_corpus = validation_dataset[\"tokens\"],\n",
    "    training_tags = training_tags,\n",
    "    validation_tags = validation_dataset[\"ner_tags\"],\n",
    "    model_name_or_path=\"distilbert-base-cased\",\n",
    "    tokenizer_name=\"distilbert-base-cased\",\n",
    "    epoch=20,\n",
    "    batch_size=32,\n",
    "    model_storage_dir=\"../models/corll_ner_no_rdrop_sampled\",\n",
    "    addtional_model_config={\"dropout\": 0.3, \"attention_dropout\": 0.3},\n",
    "    gpu_device=1,\n",
    "    warm_up_steps=500,\n",
    "    r_drop=False,\n",
    "    tensorboard_log_dir=\"../runs/corll_ner_no_rdrop_sampled\",\n",
    "    label2id={\n",
    "        \"O\": 0,\n",
    "        \"B-PER\": 1,\n",
    "        \"I-PER\": 2,\n",
    "        \"B-ORG\": 3,\n",
    "        \"I-ORG\": 4,\n",
    "        \"B-LOC\": 5,\n",
    "        \"I-LOC\": 6,\n",
    "        \"B-MISC\": 7,\n",
    "        \"I-MISC\": 8,\n",
    "    }\n",
    ")\n",
    "\n",
    "training_pipeline = NERTrainingPipeline(training_args)\n",
    "training_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbpunctuator.training import NERTrainingArguments, NERTrainingPipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "training_args = NERTrainingArguments(\n",
    "    training_corpus = train_dataset[\"tokens\"],\n",
    "    validation_corpus = validation_dataset[\"tokens\"],\n",
    "    training_tags = train_dataset[\"ner_tags\"],\n",
    "    validation_tags = validation_dataset[\"ner_tags\"],\n",
    "    model_name_or_path=\"distilbert-base-cased\",\n",
    "    tokenizer_name=\"distilbert-base-cased\",\n",
    "    epoch=20,\n",
    "    batch_size=32,\n",
    "    model_storage_dir=\"../models/corll_ner_rdrop\",\n",
    "    addtional_model_config={\"dropout\": 0.3, \"attention_dropout\": 0.3},\n",
    "    gpu_device=1,\n",
    "    warm_up_steps=500,\n",
    "    r_drop=True,\n",
    "    tensorboard_log_dir=\"../runs/corll_ner_rdrop\",\n",
    "    label2id={\n",
    "        \"O\": 0,\n",
    "        \"B-PER\": 1,\n",
    "        \"I-PER\": 2,\n",
    "        \"B-ORG\": 3,\n",
    "        \"I-ORG\": 4,\n",
    "        \"B-LOC\": 5,\n",
    "        \"I-LOC\": 6,\n",
    "        \"B-MISC\": 7,\n",
    "        \"I-MISC\": 8,\n",
    "    }\n",
    ")\n",
    "\n",
    "training_pipeline = NERTrainingPipeline(training_args)\n",
    "training_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-10 23:43:02,499 - \u001b[32mINFO\u001b[0m - evalute.py:66 - evalute.tokenize - 44779 - tokenize data\n",
      "2022-09-10 23:43:10,577 - \u001b[32mINFO\u001b[0m - evalute.py:138 - evalute._encode_tags - 44779 - encoding tags\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3453/3453 [00:00<00:00, 9346.95it/s]\n",
      "2022-09-10 23:43:10,955 - \u001b[32mINFO\u001b[0m - evalute.py:82 - evalute.validate - 44779 - start validation\n",
      "Processing batch: 108: 100%|██████████████████████████████████████████████████████████████████████████████| 108/108 [00:05<00:00, 21.34it/s, Last_batch_loss=0.13]\n",
      "2022-09-10 23:43:16,071 - \u001b[32mINFO\u001b[0m - evalute.py:132 - evalute.validate - 44779 - validation report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.8831    0.9329    0.9073      1668\n",
      "      B-MISC     0.7849    0.8162    0.8003       702\n",
      "       B-ORG     0.8830    0.8724    0.8776      1661\n",
      "       B-PER     0.9540    0.9487    0.9513      1617\n",
      "       I-LOC     0.7389    0.9027    0.8126       257\n",
      "      I-MISC     0.4861    0.7269    0.5826       216\n",
      "       I-ORG     0.8244    0.8994    0.8603       835\n",
      "       I-PER     0.9663    0.9922    0.9791      1156\n",
      "\n",
      "   micro avg     0.8729    0.9121    0.8921      8112\n",
      "   macro avg     0.8151    0.8864    0.8464      8112\n",
      "weighted avg     0.8794    0.9121    0.8945      8112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dbpunctuator.training import EvaluationArguments, EvaluationPipeline\n",
    "\n",
    "validation_args = EvaluationArguments(\n",
    "    evaluation_corpus=test_dataset[\"tokens\"],\n",
    "    evaluation_tags=test_dataset[\"ner_tags\"],\n",
    "    model_name_or_path=\"../models/corll_ner_no_rdrop_sampled\",\n",
    "    tokenizer_name=\"distilbert-base-cased\",\n",
    "    batch_size=32,\n",
    "    gpu_device=1,\n",
    ")\n",
    "\n",
    "validate_pipeline = EvaluationPipeline(validation_args)\n",
    "validate_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-10 23:12:35,885 - \u001b[32mINFO\u001b[0m - evalute.py:66 - evalute.tokenize - 44779 - tokenize data\n",
      "2022-09-10 23:12:44,473 - \u001b[32mINFO\u001b[0m - evalute.py:138 - evalute._encode_tags - 44779 - encoding tags\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3453/3453 [00:00<00:00, 9495.29it/s]\n",
      "2022-09-10 23:12:44,845 - \u001b[32mINFO\u001b[0m - evalute.py:82 - evalute.validate - 44779 - start validation\n",
      "Processing batch: 108: 100%|██████████████████████████████████████████████████████████████████████████████| 108/108 [00:04<00:00, 21.64it/s, Last_batch_loss=0.24]\n",
      "2022-09-10 23:12:49,895 - \u001b[32mINFO\u001b[0m - evalute.py:132 - evalute.validate - 44779 - validation report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.9278    0.9017    0.9146      1668\n",
      "      B-MISC     0.7334    0.8348    0.7808       702\n",
      "       B-ORG     0.8659    0.8826    0.8742      1661\n",
      "       B-PER     0.9529    0.9511    0.9520      1617\n",
      "       I-LOC     0.7835    0.8872    0.8321       257\n",
      "      I-MISC     0.4515    0.7546    0.5650       216\n",
      "       I-ORG     0.8460    0.9078    0.8758       835\n",
      "       I-PER     0.9711    0.9896    0.9803      1156\n",
      "\n",
      "   micro avg     0.8739    0.9106    0.8919      8112\n",
      "   macro avg     0.8165    0.8887    0.8468      8112\n",
      "weighted avg     0.8838    0.9106    0.8956      8112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dbpunctuator.training import EvaluationArguments, EvaluationPipeline\n",
    "\n",
    "validation_args = EvaluationArguments(\n",
    "    evaluation_corpus=test_dataset[\"tokens\"],\n",
    "    evaluation_tags=test_dataset[\"ner_tags\"],\n",
    "    model_name_or_path=\"../models/corll_ner_rdrop_sampled\",\n",
    "    tokenizer_name=\"distilbert-base-cased\",\n",
    "    batch_size=32,\n",
    "    gpu_device=1,\n",
    ")\n",
    "\n",
    "validate_pipeline = EvaluationPipeline(validation_args)\n",
    "validate_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 00:13:46,102 - \u001b[32mINFO\u001b[0m - evalute.py:66 - evalute.tokenize - 44779 - tokenize data\n",
      "2022-09-11 00:13:54,662 - \u001b[32mINFO\u001b[0m - evalute.py:138 - evalute._encode_tags - 44779 - encoding tags\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3453/3453 [00:00<00:00, 11301.89it/s]\n",
      "2022-09-11 00:13:54,976 - \u001b[32mINFO\u001b[0m - evalute.py:82 - evalute.validate - 44779 - start validation\n",
      "Processing batch: 108: 100%|██████████████████████████████████████████████████████████████████████████████| 108/108 [00:05<00:00, 21.51it/s, Last_batch_loss=0.04]\n",
      "2022-09-11 00:14:00,058 - \u001b[32mINFO\u001b[0m - evalute.py:132 - evalute.validate - 44779 - validation report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.9243    0.9371    0.9306      1668\n",
      "      B-MISC     0.8039    0.8234    0.8135       702\n",
      "       B-ORG     0.8792    0.9031    0.8910      1661\n",
      "       B-PER     0.9648    0.9505    0.9576      1617\n",
      "       I-LOC     0.8417    0.9105    0.8748       257\n",
      "      I-MISC     0.5933    0.7361    0.6570       216\n",
      "       I-ORG     0.8141    0.9234    0.8653       835\n",
      "       I-PER     0.9736    0.9879    0.9807      1156\n",
      "\n",
      "   micro avg     0.8936    0.9226    0.9079      8112\n",
      "   macro avg     0.8494    0.8965    0.8713      8112\n",
      "weighted avg     0.8970    0.9226    0.9091      8112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dbpunctuator.training import EvaluationArguments, EvaluationPipeline\n",
    "\n",
    "validation_args = EvaluationArguments(\n",
    "    evaluation_corpus=test_dataset[\"tokens\"],\n",
    "    evaluation_tags=test_dataset[\"ner_tags\"],\n",
    "    model_name_or_path=\"../models/corll_ner_no_rdrop\",\n",
    "    tokenizer_name=\"distilbert-base-cased\",\n",
    "    batch_size=32,\n",
    "    gpu_device=1,\n",
    ")\n",
    "\n",
    "validate_pipeline = EvaluationPipeline(validation_args)\n",
    "validate_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 00:14:13,330 - \u001b[32mINFO\u001b[0m - evalute.py:66 - evalute.tokenize - 44779 - tokenize data\n",
      "2022-09-11 00:14:20,863 - \u001b[32mINFO\u001b[0m - evalute.py:138 - evalute._encode_tags - 44779 - encoding tags\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3453/3453 [00:00<00:00, 12193.31it/s]\n",
      "2022-09-11 00:14:21,154 - \u001b[32mINFO\u001b[0m - evalute.py:82 - evalute.validate - 44779 - start validation\n",
      "Processing batch: 108: 100%|██████████████████████████████████████████████████████████████████████████████| 108/108 [00:05<00:00, 21.28it/s, Last_batch_loss=0.21]\n",
      "2022-09-11 00:14:26,287 - \u001b[32mINFO\u001b[0m - evalute.py:132 - evalute.validate - 44779 - validation report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.9273    0.9323    0.9297      1668\n",
      "      B-MISC     0.7931    0.8462    0.8187       702\n",
      "       B-ORG     0.9106    0.8832    0.8967      1661\n",
      "       B-PER     0.9404    0.9666    0.9533      1617\n",
      "       I-LOC     0.7940    0.9300    0.8566       257\n",
      "      I-MISC     0.5270    0.7685    0.6252       216\n",
      "       I-ORG     0.8878    0.8910    0.8894       835\n",
      "       I-PER     0.9696    0.9931    0.9812      1156\n",
      "\n",
      "   micro avg     0.8967    0.9216    0.9090      8112\n",
      "   macro avg     0.8437    0.9013    0.8689      8112\n",
      "weighted avg     0.9020    0.9216    0.9108      8112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dbpunctuator.training import EvaluationArguments, EvaluationPipeline\n",
    "\n",
    "validation_args = EvaluationArguments(\n",
    "    evaluation_corpus=test_dataset[\"tokens\"],\n",
    "    evaluation_tags=test_dataset[\"ner_tags\"],\n",
    "    model_name_or_path=\"../models/corll_ner_rdrop\",\n",
    "    tokenizer_name=\"distilbert-base-cased\",\n",
    "    batch_size=32,\n",
    "    gpu_device=1,\n",
    ")\n",
    "\n",
    "validate_pipeline = EvaluationPipeline(validation_args)\n",
    "validate_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "punctuator",
   "language": "python",
   "name": "punctuator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
